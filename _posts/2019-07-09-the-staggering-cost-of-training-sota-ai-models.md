---
layout: post
date: "2019-07-09"
author: "Prathyush SP"
link: "https://medium.com/syncedreview/the-staggering-cost-of-training-sota-ai-models-e329e80fa82"
category: "Resource"
title: "The Staggering Cost of Training SOTA AI Models"
tags: ""
comments: true
---
Synced recently reported on XLNet, a new language model developed by CMU and Google Research which outperforms the previous SOTA model BERT (Bidirectional Encoder Representations from Transformers) on 20 language tasks including SQuAD, GLUE, and RACE; and has achieved SOTA results on 18 of these tasks.