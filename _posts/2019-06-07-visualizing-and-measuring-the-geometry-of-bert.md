---
layout: post
date: "2019-06-07"
author: "Prathyush SP"
link: "https://arxiv.org/pdf/1906.02715.pdf"
category: "Paper"
title: "Visualizing and Measuring the Geometry of BERT"
tags: ""
comments: true
---
Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on
many different tasks, these networks appear to extract generally useful linguistic
features. A natural question is how such networks represent this information internally.